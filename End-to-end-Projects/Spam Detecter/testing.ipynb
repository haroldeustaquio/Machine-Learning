{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading and Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/fraud_email_train.csv',low_memory=False)\n",
    "test = pd.read_csv(\"data/fraud_email_test.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "# train.describe()\n",
    "# train.info()\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['Label'].value_counts())\n",
    "print(test['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a column as an data_ID: `train` and `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['data_ID'] ='train'\n",
    "test['data_ID'] = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat `train` and `test` into `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Droppping Columns from data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = {'Folder-User','Folder-Name','Message-ID','Mime-Version','Content-Type','Content-Transfer-Encoding','Contains-Reply-Forwards',\n",
    "                'X-FileName','X-Folder','X-From','X-Origin', 'Low-Comm','X-To','X-bcc','X-cc','Date','Suspicious-Folders','Mail-ID','Source','Cc',\n",
    "                'Time','Attendees','Re','Unique-Mails-From-Sender'}\n",
    "\n",
    "data.drop(columns=columns_to_drop,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.duplicated().sum())\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformating `From` and `To`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['From'] = data['From'].str.replace('.', ' ').str.replace('@', ' ').str.replace('com', '')\n",
    "data['To'] = data['To'].str.replace('.', ' ').str.replace('@', ' ').str.replace('com', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating new column: `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['POI-Present', 'Sender-Type', 'Unique-Mails-From-Sender', 'Label']\n",
    "data['text'] = data['From'] + ' ' + data['Body'] + ' ' + data['To'] + ' ' + data['Bcc'] +' ' + data['Subject']\n",
    "\n",
    "data.drop(columns=['From','Body','To','Bcc','Subject'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting punctuaction of column `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.lower().replace(f'[{punctuation}]','',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop nan values in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset='text',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing `POI-Present`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['POI-Present'] = data['POI-Present'].map({False:0,True:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reorder the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text','POI-Present','Sender-Type','Label','data_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sender-Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting in `train_clean` and `test_clean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = data[data['data_ID'] == 'train'].drop(columns='data_ID')\n",
    "test_clean = data[data['data_ID']=='test'].drop(columns='data_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 4. Splitting and Vectorizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_clean.drop(columns='Label')\n",
    "y_train = train_clean['Label'] \n",
    "x_test = test_clean.drop(columns='Label')\n",
    "y_test = test_clean['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "x_train_text_vecto = vectorizer.fit_transform(x_train['text'])\n",
    "x_test_text_vecto = vectorizer.transform(x_test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 5. Model Building and Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(x_train_text_vecto,y_train)\n",
    "predictions = model.predict(x_test_text_vecto)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "model_name = 'NB - Multinomial'\n",
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(x_train_text_vecto,y_train)\n",
    "predictions = model.predict(x_test_text_vecto)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "model_name = 'Decision Tree - entropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(x_train_text_vecto,y_train)\n",
    "predictions = model.predict(x_test_text_vecto)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "model_name = 'Decision Tree - entropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='sigmoid')\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(x_train_text_vecto,y_train)\n",
    "predictions = model.predict(x_test_text_vecto)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "\n",
    "model_name = 'SVM - kernel: sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
