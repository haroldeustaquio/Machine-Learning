{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, f1_score, recall_score\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading and Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data = pd.read_csv('data/True.csv')\n",
    "fake_data = pd.read_csv('data/Fake.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a new column called `output`, 1 for true_data and 0 for fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data['output'] = 1\n",
    "fake_data['output'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat `true_data` and `fake_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([true_data,fake_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete duplicated rows and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()    # 209 duplicated rows\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "data.duplicated(subset=['text']).sum() # 6043 duplicated rows \n",
    "\n",
    "data.drop_duplicates(subset=['text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any(axis=1).sum()  # there are no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete blank text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by='text',inplace=True)\n",
    "data = data[data.text.str.strip() != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a new column called `complete_text`, and drop `text` and `title` from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['complete_text'] =data['title'] + ' ' + data['text']\n",
    "\n",
    "data.drop(columns=['text','title'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the punctuation from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = string.punctuation + '‘’-“”'\n",
    "data['complete_text'] = data['complete_text'].str.lower().replace(f'[{punctuation}]','',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test delete duplicated rows with subset = 'title'\n",
    "# data[data.duplicated(subset=['title'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 4. Splitting and Vectorizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.complete_text.values\n",
    "y = data.output\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "x_train_vect = vectorizer.fit_transform(x_train)\n",
    "\n",
    "x_test_vect = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 5. Model Building and Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_description = []\n",
    "\n",
    "def save_info_evaluation(duration,model_name, y_test,predictions):\n",
    "    accuracy = accuracy_score(y_test,predictions)\n",
    "    precision = precision_score(y_test,predictions)\n",
    "    recall = recall_score(y_test,predictions)\n",
    "    f1score = f1_score(y_test,predictions)\n",
    "\n",
    "    model_description.append([model_name,duration,accuracy,precision,recall,f1score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(x_train_vect,y_train)\n",
    "predictions = model.predict(x_test_vect)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "model_name = 'NB - Multinomial with alpha = 1 (per default)'\n",
    "save_info_evaluation(duration,model_name, y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Improve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'alpha': [0.1,0.01,0.001,0.0001,0.00001],\n",
    "}\n",
    "\n",
    "gridsearch = GridSearchCV(model, param_grid=params,scoring='accuracy', cv=5,n_jobs=-1,verbose=1)\n",
    "\n",
    "start_time = time.time()\n",
    "gridsearch.fit(x_train_vect,y_train)\n",
    "predictions = gridsearch.predict(x_test_vect)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'NB - Multinomial with {gridsearch.best_params_}'\n",
    "save_info_evaluation(duration,model_name, y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `criterion = 'entropy'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(x_train_vect,y_train)\n",
    "predictions = model.predict(x_test_vect)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "model_name = 'Decision Tree - entropy'\n",
    "save_info_evaluation(duration,model_name, y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `criterion = 'gini'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(x_train_vect,y_train)\n",
    "predictions = model.predict(x_test_vect)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "model_name = 'Decision Tree - gini'\n",
    "save_info_evaluation(duration,model_name, y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `kernel: linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(x_train_vect,y_train)\n",
    "predictions = model.predict(x_test_vect)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "model_name = 'SVM - kernel: linear'\n",
    "save_info_evaluation(duration,model_name, y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `kernel: sigmoid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='sigmoid')\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(x_train_vect,y_train)\n",
    "predictions = model.predict(x_test_vect)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "model_name = 'SVM - kernel: sigmoid'\n",
    "save_info_evaluation(duration,model_name, y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `solver: sag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Proyectos\\DMC\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='sag')\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(x_train_vect,y_train)\n",
    "predictions = model.predict(x_test_vect)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "model_name = 'Log. Regression - solver: sag'\n",
    "save_info_evaluation(duration,model_name, y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `solver: newton`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='newton-cg')\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(x_train_vect,y_train)\n",
    "predictions = model.predict(x_test_vect)\n",
    "end_time = time.time()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "model_name = 'Log. Regression - solver: newton-cg'\n",
    "save_info_evaluation(duration,model_name, y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, I prefer to use `Decision Tree: Gini` or `Log. Regression - solver: Newton-CG`, both have similar metrics, however the main difference is the duration, we also need to avoid overfitting models, to solve this we need to get more data or use cross validation for each of these 2 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_model</th>\n",
       "      <th>duration</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree - gini</td>\n",
       "      <td>16.264010</td>\n",
       "      <td>0.995756</td>\n",
       "      <td>0.994493</td>\n",
       "      <td>0.997714</td>\n",
       "      <td>0.996101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Log. Regression - solver: newton-cg</td>\n",
       "      <td>7.245300</td>\n",
       "      <td>0.995342</td>\n",
       "      <td>0.994113</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.995720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM - kernel:linear</td>\n",
       "      <td>140.312686</td>\n",
       "      <td>0.995032</td>\n",
       "      <td>0.993735</td>\n",
       "      <td>0.997142</td>\n",
       "      <td>0.995436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree - entropy</td>\n",
       "      <td>7.924360</td>\n",
       "      <td>0.993893</td>\n",
       "      <td>0.993158</td>\n",
       "      <td>0.995618</td>\n",
       "      <td>0.994387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Log. Regression - solver: sag</td>\n",
       "      <td>14.505118</td>\n",
       "      <td>0.992858</td>\n",
       "      <td>0.990902</td>\n",
       "      <td>0.995999</td>\n",
       "      <td>0.993444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB - Multinomial with {'alpha': 1e-05}</td>\n",
       "      <td>7.504513</td>\n",
       "      <td>0.965532</td>\n",
       "      <td>0.971062</td>\n",
       "      <td>0.965327</td>\n",
       "      <td>0.968186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB - Multinomial with alpha = 1 (per default)</td>\n",
       "      <td>0.110550</td>\n",
       "      <td>0.954249</td>\n",
       "      <td>0.950178</td>\n",
       "      <td>0.966470</td>\n",
       "      <td>0.958255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM - kernel: sigmoid</td>\n",
       "      <td>143.787991</td>\n",
       "      <td>0.949488</td>\n",
       "      <td>0.951451</td>\n",
       "      <td>0.955801</td>\n",
       "      <td>0.953621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name_model    duration  accuracy  \\\n",
       "3                           Decision Tree - gini   16.264010  0.995756   \n",
       "7            Log. Regression - solver: newton-cg    7.245300  0.995342   \n",
       "4                            SVM - kernel:linear  140.312686  0.995032   \n",
       "2                        Decision Tree - entropy    7.924360  0.993893   \n",
       "6                  Log. Regression - solver: sag   14.505118  0.992858   \n",
       "1         NB - Multinomial with {'alpha': 1e-05}    7.504513  0.965532   \n",
       "0  NB - Multinomial with alpha = 1 (per default)    0.110550  0.954249   \n",
       "5                          SVM - kernel: sigmoid  143.787991  0.949488   \n",
       "\n",
       "   precision    recall   f1score  \n",
       "3   0.994493  0.997714  0.996101  \n",
       "7   0.994113  0.997333  0.995720  \n",
       "4   0.993735  0.997142  0.995436  \n",
       "2   0.993158  0.995618  0.994387  \n",
       "6   0.990902  0.995999  0.993444  \n",
       "1   0.971062  0.965327  0.968186  \n",
       "0   0.950178  0.966470  0.958255  \n",
       "5   0.951451  0.955801  0.953621  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(model_description,columns=['name_model','duration','accuracy','precision','recall','f1score'])\n",
    "df.sort_values(by=['accuracy'],ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
